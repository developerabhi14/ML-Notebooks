{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNee0cZRYGW9B88QcdyRx1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/developerabhi14/ML-Notebooks/blob/main/ChatGPT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FF_Epcwpjre",
        "outputId": "4a9ca290-af2c-442e-daa4-4da9565bf34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-23 07:51:45--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-03-23 07:51:45 (17.0 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input.txt\", \"r\", encoding= \"utf-8\") as f:\n",
        "  text=f.read()"
      ],
      "metadata": {
        "id": "Hoea3esHqGjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IdkNtWAqRWY",
        "outputId": "3a51ab01-5908-45a8-8abc-62e35206ee01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "1C2GardQqTa0",
        "outputId": "da418334-f9e9-45a3-9f82-7698f1c26341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN9Ow4npqW-G",
        "outputId": "d0ef8d80-cda4-408a-ce15-d8759e4a7457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping frm characters to integers\n",
        "stoi={ ch:i for i, ch in enumerate(chars) }\n",
        "itos={ i:ch for i, ch in enumerate(chars) }\n",
        "encode=lambda s: [stoi[c] for c in s] #encoder takes a string, outputs a list of integers\n",
        "decode=lambda l: ''.join([itos[i] for i in l]) # decoder: takes a list of integers, outputs a string\n",
        "\n",
        "print(encode(\"hello\"))\n",
        "print(decode(encode(\"hello\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTI-p80HqkmW",
        "outputId": "6dc9e7d6-4439-45fa-ea8a-5e1fa8c81c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 43, 50, 50, 53]\n",
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data=torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.type)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7HxRoyprORm",
        "outputId": "f78f4827-f689-47c7-bd53-3d1f4b0e8ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) <built-in method type of Tensor object at 0x78ee5267d9d0>\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split into test and train\n",
        "n=int(0.9*len(data)) # first 90% will be train, rest will be val\n",
        "train_data=data[:n]\n",
        "val_data=data[n:]"
      ],
      "metadata": {
        "id": "SnZ19bFbr7fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size=8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt3YwIJ4wybO",
        "outputId": "6d005bf2-2ad4-41b6-9e6f-19419b586b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=train_data[:block_size]\n",
        "y=train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context=x[:t+1]\n",
        "  target=y[t]\n",
        "  print(f\"when input is {context} target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0YrBmHkw1vs",
        "outputId": "95defc1b-2e96-4e5a-cb8f-463be983a676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) target is 47\n",
            "when input is tensor([18, 47]) target is 56\n",
            "when input is tensor([18, 47, 56]) target is 57\n",
            "when input is tensor([18, 47, 56, 57]) target is 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) target is 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) target is 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) target is 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) target is 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch dimension for parallel processing, process multiple chunks at the same time\n",
        "\n",
        "torch.manual_seed(1300)\n",
        "batch_size=4 # how many independent sequences will we process in parallel\n",
        "block_size=8 # what is the maximum context length for predictions\n",
        "\n",
        "def get_batch(split):\n",
        "  # generate a small batch of ata of inputs x and targets y\n",
        "  data=train_data if split==\"train\" else val_data\n",
        "  ix=torch.randint(len(data)-block_size, (batch_size,))\n",
        "  x=torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb, yb=get_batch(\"train\")\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print(\"-------\")\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "  for t in range(block_size): #time dimension\n",
        "    context=xb[b, :t+1]\n",
        "    target=yb[b,t]\n",
        "    print(f\"when input is {context.tolist()} the target is {target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wt-TKfAxUhy",
        "outputId": "9c370eda-8825-49ed-9ee0-9920e9d73ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 0, 57, 53,  1, 58, 46, 39, 58],\n",
            "        [39, 56, 58, 46,  8,  0, 27,  6],\n",
            "        [17, 17, 26,  1, 17, 24, 21, 38],\n",
            "        [43,  1, 57, 43, 52, 58, 43, 52]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[57, 53,  1, 58, 46, 39, 58,  1],\n",
            "        [56, 58, 46,  8,  0, 27,  6,  1],\n",
            "        [17, 26,  1, 17, 24, 21, 38, 13],\n",
            "        [ 1, 57, 43, 52, 58, 43, 52, 41]])\n",
            "-------\n",
            "when input is [0] the target is 57\n",
            "when input is [0, 57] the target is 53\n",
            "when input is [0, 57, 53] the target is 1\n",
            "when input is [0, 57, 53, 1] the target is 58\n",
            "when input is [0, 57, 53, 1, 58] the target is 46\n",
            "when input is [0, 57, 53, 1, 58, 46] the target is 39\n",
            "when input is [0, 57, 53, 1, 58, 46, 39] the target is 58\n",
            "when input is [0, 57, 53, 1, 58, 46, 39, 58] the target is 1\n",
            "when input is [39] the target is 56\n",
            "when input is [39, 56] the target is 58\n",
            "when input is [39, 56, 58] the target is 46\n",
            "when input is [39, 56, 58, 46] the target is 8\n",
            "when input is [39, 56, 58, 46, 8] the target is 0\n",
            "when input is [39, 56, 58, 46, 8, 0] the target is 27\n",
            "when input is [39, 56, 58, 46, 8, 0, 27] the target is 6\n",
            "when input is [39, 56, 58, 46, 8, 0, 27, 6] the target is 1\n",
            "when input is [17] the target is 17\n",
            "when input is [17, 17] the target is 26\n",
            "when input is [17, 17, 26] the target is 1\n",
            "when input is [17, 17, 26, 1] the target is 17\n",
            "when input is [17, 17, 26, 1, 17] the target is 24\n",
            "when input is [17, 17, 26, 1, 17, 24] the target is 21\n",
            "when input is [17, 17, 26, 1, 17, 24, 21] the target is 38\n",
            "when input is [17, 17, 26, 1, 17, 24, 21, 38] the target is 13\n",
            "when input is [43] the target is 1\n",
            "when input is [43, 1] the target is 57\n",
            "when input is [43, 1, 57] the target is 43\n",
            "when input is [43, 1, 57, 43] the target is 52\n",
            "when input is [43, 1, 57, 43, 52] the target is 58\n",
            "when input is [43, 1, 57, 43, 52, 58] the target is 43\n",
            "when input is [43, 1, 57, 43, 52, 58, 43] the target is 52\n",
            "when input is [43, 1, 57, 43, 52, 58, 43, 52] the target is 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1300)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    logits=self.token_embedding_table(idx) # (B,T,C)\n",
        "    if targets is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      # pytorch expects()\n",
        "      B,T,C=logits.shape\n",
        "      logits=logits.view(B*T, C)\n",
        "      targets=targets.view(B*T)\n",
        "      loss=F.cross_entropy(logits, targets)\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      # get the predictions\n",
        "      logits,loss=self(idx)\n",
        "      # focus only on last time step\n",
        "      logits=logits[:,-1,:] #becomes (B,C)\n",
        "      # apply softmax to get probabilities\n",
        "      probs=F.softmax(logits, dim=-1) #(B,C)\n",
        "      # sample the distribution\n",
        "      idx_next=torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "      # append sampled index to the running sequence\n",
        "      idx=torch.cat((idx, idx_next), dim=1) # (B,T+1)\n",
        "    return idx\n",
        "\n",
        "m=BigramLanguageModel(vocab_size)\n",
        "logits, loss=m(xb,yb)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYO9zUxyy4Uv",
        "outputId": "a25ed7a6-bab7-4749-d3f2-f19adc8e6dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.5309, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX07mhV1z6J9",
        "outputId": "ce4ebb0b-1e0f-456c-e5e3-7a98c3739428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "m\n",
            "HRsrBZk:'L!KWcQ\n",
            "Hc.XpRWAYMr sbzHGRmW:R\n",
            "mqbzwBtnCPIfZ.X-f,uc-c;iylIjjMpZO?VKN! FzTeOukZBHZhD$ddZWzC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "gLnBP-G_JxyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "for steps in range(10000):\n",
        "  xb,yb=get_batch('train')\n",
        "  # evaluate the loss\n",
        "  logits, loss=m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZs4EfshKLLD",
        "outputId": "59178420-94f9-45e0-cb73-5d24c3fb4964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.436859130859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(idx, max_new_tokens=300)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RFnudooKmQr",
        "outputId": "51e9578c-ef5b-42e4-b164-22b6470bb0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OTAn.\n",
            "Hothat mout havescor atemar d.\n",
            "ISOPand d cod toverd t grth a ye windarimat nt tesacelom trf ts HORotursovelens n,Anllod dllomyprayoreild:\n",
            "ENEdr booom issuld lowown hallir boxcend berd thmito irvaie\n",
            "Ma pooro;\n",
            "S:\n",
            "Cisimatomecel sur's f do. tAy o ie nd acorese br re, fr or atratheathan t ir,\n",
            "IOUCi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2g0aO6yK5iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simplest model because the tokens are not talking to each other\n",
        "\n",
        "# The mathematical trick in self Attention"
      ],
      "metadata": {
        "id": "l0eykXX9LGoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1300)\n",
        "B,T,C=4,8,2 # batch , time , channels\n",
        "x=torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8BblPwMLKgZ",
        "outputId": "83ef67a1-3ce3-47ae-f2b8-d699006b2db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens should talk to past tokens only,context should flow from past to present\n",
        "# just do average of previous tokens, that would be feature vector, that would summarize the context\n",
        "# altough lossy but its ok for now"
      ],
      "metadata": {
        "id": "aH0EC8Hvo2UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow=torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev=x[b,:t+1] #(t,C)\n",
        "    xbow[b,t]=torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "ASuG50Hypuhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5BmQLZzAaCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g70-YC2eAaIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyXDdn6-qMWG",
        "outputId": "060d3fd9-ecbc-409b-d0c2-248646c430aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2028, -1.4443],\n",
              "        [-0.5584, -1.0433],\n",
              "        [ 0.2127,  0.4175],\n",
              "        [-0.6576,  1.3523],\n",
              "        [ 0.0918, -1.1213],\n",
              "        [-1.5167,  1.1398],\n",
              "        [ 0.4244,  0.8652],\n",
              "        [ 0.6012,  0.8964]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anzWNlcZqTt_",
        "outputId": "283c8ae1-fc6f-4a8f-d547-e3aa56740181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2028, -1.4443],\n",
              "        [-0.3806, -1.2438],\n",
              "        [-0.1828, -0.6900],\n",
              "        [-0.3015, -0.1795],\n",
              "        [-0.2229, -0.3678],\n",
              "        [-0.4385, -0.1166],\n",
              "        [-0.3152,  0.0237],\n",
              "        [-0.2007,  0.1328]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# very inefficient process\n",
        "# efficient using matrix multiplication\n",
        "torch.manual_seed(42)\n",
        "a=torch.ones(3,3)\n",
        "b=torch.randint(0,10,(3,2)).float()\n",
        "c= a @ b\n",
        "print(\"a=\")\n",
        "print(a)\n",
        "print(\"b=\")\n",
        "print(b)\n",
        "print(\"c=\")\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuBARcoxqVHG",
        "outputId": "f26da085-99a8-4ae4-ae76-c9a41d6da848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "c=\n",
            "tensor([[14., 16.],\n",
            "        [14., 16.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the trick here is following\n",
        "#we get the lower traingular part\n",
        "torch.tril(torch.ones(3,3))"
      ],
      "metadata": {
        "id": "3uuFnoburGYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40232c0-a7c1-4a75-ef62-524ffc85e249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a=torch.tril(torch.ones(3,3))\n",
        "a=a/torch.sum(a,1, keepdim=True)\n",
        "b=torch.randint(0,10,(3,2)).float()\n",
        "c= a @ b\n",
        "print(\"a=\")\n",
        "print(a)\n",
        "print(\"b=\")\n",
        "print(b)\n",
        "print(\"c=\")\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXebUPJB_duT",
        "outputId": "3af8caae-4c3f-4c5b-d820-0f45fd93e17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying this trick above\n",
        "# version 2\n",
        "torch.manual_seed(1337)\n",
        "B,T,C=4,8,2 # batch , time , channels\n",
        "x=torch.randn(B,T,C)\n",
        "x.shape\n",
        "\n",
        "\n",
        "xbow=torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev=x[b,:t+1] #(t,C)\n",
        "    xbow[b,t]=torch.mean(xprev, 0)\n",
        "\n",
        "print(xbow.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZCk9G7g_o_Y",
        "outputId": "ade5fac0-0bc9-419a-c758-55fb1f69590f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wei=torch.tril(torch.ones(T,T))\n",
        "wei=wei/wei.sum(1,keepdim=True)\n",
        "\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o60lIKklAhnA",
        "outputId": "b2ab33f6-32d4-4c5f-9f44-5de013401107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2=wei @ x # (T,T) @ (B,T,C) ----> (B,T,T) @ (B,T,C) ----> (B,T,C) xbow2 will be identical to xbow\n",
        "torch.allclose(xbow, xbow2)\n",
        "print(xbow2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dti3TVCAt4q",
        "outputId": "b5b3732b-9277-4eef-86bb-0748d8065a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0], xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAfYIUgKBD-w",
        "outputId": "032f708e-b73b-4999-d062-b5f6c6b395bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]),\n",
              " tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3\n",
        "torch.manual_seed(1337)\n",
        "B,T,C=4,8,2 # batch , time , channels\n",
        "x=torch.randn(B,T,C)\n",
        "x.shape\n",
        "\n",
        "\n",
        "xbow=torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev=x[b,:t+1] #(t,C)\n",
        "    xbow[b,t]=torch.mean(xprev, 0)\n",
        "\n",
        "tril=torch.tril(torch.ones(T,T))\n",
        "wei=torch.zeros((T,T))\n",
        "wei=wei.masked_fill(tril==0, float('-inf'))\n",
        "print(wei)\n",
        "wei=F.softmax(wei, dim=-1)\n",
        "print(wei)\n",
        "xbow3=wei @ x\n",
        "xbow[0],xbow2[0],  xbow3[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-q8y6T-Bd9q",
        "outputId": "18cae616-b404-4126-fa60-caeaa8beaabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]),\n",
              " tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]),\n",
              " tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# v4: Self atttention\n",
        "torch.manual_seed(1337)\n",
        "B,T,C=4,8,32 # batch , time , channels\n",
        "x=torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self attention\n",
        "head_size=16\n",
        "key=nn.Linear(C, head_size, bias=False)\n",
        "query=nn.Linear(C, head_size, bias=False)\n",
        "value=nn.Linear(C, head_size, bias=False)\n",
        "k=key(x) #(B,T,16)\n",
        "q=query(x) # (B,T,16)\n",
        "\n",
        "wei=q @ k.transpose(-2,-1) #(B,T,16) @ (B,16,T) ----> (B,T,T)\n",
        "print(\"Wei kq:\",wei)\n",
        "tril=torch.tril(torch.ones(T,T))\n",
        "print(\"tril\",tril)\n",
        "# but i dont want this to be consistent\n",
        "# wei=torch.zeros((T,T))\n",
        "wei =wei.masked_fill(tril==0, float('-inf'))\n",
        "print('wei masked fill', wei)\n",
        "wei=F.softmax(wei, dim=-1)\n",
        "print('wei softmax', wei)\n",
        "v=value(x)\n",
        "out=wei @ v\n",
        "\n",
        "print('out', out)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CpFPAi-CLQx",
        "outputId": "1612fa28-0fff-4bbe-e865-0b2dd9143a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wei kq: tensor([[[-1.7629e+00, -1.3011e+00,  5.6516e-01,  2.1616e+00, -1.0674e+00,\n",
            "           1.9632e+00,  1.0765e+00, -4.5295e-01],\n",
            "         [-3.3334e+00, -1.6556e+00,  1.0405e-01,  3.3782e+00, -2.1825e+00,\n",
            "           1.0415e+00, -5.5714e-02,  2.9273e-01],\n",
            "         [-1.0226e+00, -1.2606e+00,  7.6228e-02, -3.8125e-01, -9.8430e-01,\n",
            "          -1.4303e+00,  7.4921e-02, -9.5465e-01],\n",
            "         [ 7.8359e-01, -8.0143e-01, -3.3680e-01, -8.4963e-01, -5.6023e-01,\n",
            "          -1.1701e+00, -1.2927e+00, -1.0260e+00],\n",
            "         [-1.2566e+00,  1.8719e-02, -7.8797e-01, -1.3204e+00,  2.0363e+00,\n",
            "           8.6381e-01,  3.7188e-01,  9.2577e-01],\n",
            "         [-3.1262e-01,  2.4152e+00, -1.1058e-01, -9.9305e-01,  3.3449e+00,\n",
            "          -2.5229e+00,  1.4187e+00,  1.2196e+00],\n",
            "         [ 1.0876e+00,  1.9652e+00, -2.6213e-01, -3.1579e-01,  6.0905e-01,\n",
            "           1.2616e+00, -5.4841e-01,  8.0485e-01],\n",
            "         [-1.8044e+00, -4.1260e-01, -8.3061e-01,  5.8985e-01, -7.9869e-01,\n",
            "          -5.8560e-01,  6.4332e-01,  6.3028e-01]],\n",
            "\n",
            "        [[-7.3529e-01, -1.7807e+00,  1.0745e+00, -2.7429e-01,  1.6347e+00,\n",
            "           1.4177e+00, -5.5213e-01, -2.3580e+00],\n",
            "         [-3.0892e+00, -1.4943e+00, -2.6167e-01,  2.2760e+00, -2.4364e-01,\n",
            "           1.6198e-01,  2.5783e+00,  3.9591e-01],\n",
            "         [-5.0206e-01, -2.0745e+00,  5.3785e-01, -4.0494e-01,  8.3292e-01,\n",
            "           1.3570e+00, -1.5621e+00, -1.6490e+00],\n",
            "         [ 1.3810e+00, -1.4713e-01,  1.2181e+00, -2.2266e-01, -1.8247e+00,\n",
            "          -3.7044e+00, -2.1321e+00,  1.3178e+00],\n",
            "         [-2.3568e+00, -4.6170e-01, -8.8196e-01,  2.3700e+00,  6.7828e-01,\n",
            "           1.6262e-01,  1.9379e+00,  1.0397e-01],\n",
            "         [-9.2435e-01, -6.2351e-01, -1.3938e+00,  1.3336e+00, -8.9731e-03,\n",
            "          -3.1789e+00,  9.0259e-01,  3.6256e+00],\n",
            "         [-6.5522e-01,  1.0991e+00, -2.1399e+00,  9.6468e-01,  9.9463e-01,\n",
            "           9.3899e-01,  4.6799e-01, -3.5870e-01],\n",
            "         [ 1.5463e+00, -4.9438e-01, -1.4180e-02, -9.7428e-01,  1.3779e+00,\n",
            "           7.8648e-03, -5.3590e-01, -4.5531e-01]],\n",
            "\n",
            "        [[-3.7898e-01,  5.1592e-01,  3.0332e-01,  1.1303e+00,  2.0511e+00,\n",
            "           2.2323e+00,  3.1239e+00, -1.2231e+00],\n",
            "         [ 1.0377e-01,  1.7584e-01, -1.6369e-01,  5.2328e-01, -2.2172e+00,\n",
            "          -8.7770e-01,  1.7020e-01, -1.0842e+00],\n",
            "         [-1.6373e+00, -6.5557e-01, -8.5031e-01,  2.3457e+00, -9.9497e-01,\n",
            "          -4.9228e-02,  5.5157e-01,  1.5285e+00],\n",
            "         [-2.7155e+00,  1.9022e+00, -8.4620e-01,  5.9058e-01,  2.1122e+00,\n",
            "           8.8971e-01, -2.0679e+00, -7.4249e-01],\n",
            "         [ 2.5044e+00, -4.9691e-01, -2.6300e-01, -1.6288e-01, -1.7459e+00,\n",
            "           8.6298e-02,  2.7739e+00, -2.4952e-02],\n",
            "         [-4.8634e-02,  4.9620e-01, -2.0859e-01, -8.4632e-02,  3.6811e-01,\n",
            "           7.8713e-01, -1.9678e-01,  4.1090e-01],\n",
            "         [-1.7485e+00,  4.6233e-01,  3.8654e-03,  2.1114e+00,  1.2731e+00,\n",
            "           2.1582e+00,  1.3125e+00,  2.0600e+00],\n",
            "         [-8.5500e-02, -1.5414e-02, -1.3915e+00,  6.3086e-02, -2.4530e-01,\n",
            "          -2.0677e-01, -2.2102e+00,  4.4531e-01]],\n",
            "\n",
            "        [[ 4.5165e-01,  3.2148e-01, -3.1926e+00,  3.0765e-01, -6.1612e-01,\n",
            "           2.5626e-01, -2.9891e-01, -2.1917e+00],\n",
            "         [-4.0009e-01, -9.6205e-01,  1.9568e+00,  6.6612e-01, -3.2630e-01,\n",
            "           2.6258e-01, -1.3973e+00, -8.9450e-01],\n",
            "         [-4.6199e-01,  5.8600e-01, -4.6738e+00, -3.2178e-01,  1.2684e+00,\n",
            "          -1.7402e-01,  1.2461e+00, -2.2283e+00],\n",
            "         [-7.1746e-01, -1.0279e+00, -2.0509e+00, -2.7234e+00,  3.1231e-01,\n",
            "          -1.6416e-01,  1.5162e+00, -7.7670e-01],\n",
            "         [-4.0388e-01,  5.1597e-01, -2.0697e+00, -4.0982e-01, -8.0534e-01,\n",
            "           5.2210e-01, -4.1242e-01,  1.3377e+00],\n",
            "         [ 8.2322e-01,  3.0237e+00, -3.0655e+00,  7.0404e-01,  6.7207e-01,\n",
            "          -4.6692e-01,  2.3746e+00,  3.1181e-01],\n",
            "         [-1.4141e+00, -1.4241e+00, -8.0387e-01, -1.7450e+00, -7.4035e-01,\n",
            "           9.8188e-01, -9.0056e-01, -2.3158e+00],\n",
            "         [-5.0277e-01,  1.6844e+00, -4.1847e-01,  1.0239e+00,  1.0275e+00,\n",
            "           1.3980e-01,  4.8822e-01,  1.5573e+00]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "tril tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "wei masked fill tensor([[[-1.7629e+00,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-3.3334e+00, -1.6556e+00,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.0226e+00, -1.2606e+00,  7.6228e-02,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 7.8359e-01, -8.0143e-01, -3.3680e-01, -8.4963e-01,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.2566e+00,  1.8719e-02, -7.8797e-01, -1.3204e+00,  2.0363e+00,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-3.1262e-01,  2.4152e+00, -1.1058e-01, -9.9305e-01,  3.3449e+00,\n",
            "          -2.5229e+00,        -inf,        -inf],\n",
            "         [ 1.0876e+00,  1.9652e+00, -2.6213e-01, -3.1579e-01,  6.0905e-01,\n",
            "           1.2616e+00, -5.4841e-01,        -inf],\n",
            "         [-1.8044e+00, -4.1260e-01, -8.3061e-01,  5.8985e-01, -7.9869e-01,\n",
            "          -5.8560e-01,  6.4332e-01,  6.3028e-01]],\n",
            "\n",
            "        [[-7.3529e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-3.0892e+00, -1.4943e+00,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-5.0206e-01, -2.0745e+00,  5.3785e-01,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 1.3810e+00, -1.4713e-01,  1.2181e+00, -2.2266e-01,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-2.3568e+00, -4.6170e-01, -8.8196e-01,  2.3700e+00,  6.7828e-01,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-9.2435e-01, -6.2351e-01, -1.3938e+00,  1.3336e+00, -8.9731e-03,\n",
            "          -3.1789e+00,        -inf,        -inf],\n",
            "         [-6.5522e-01,  1.0991e+00, -2.1399e+00,  9.6468e-01,  9.9463e-01,\n",
            "           9.3899e-01,  4.6799e-01,        -inf],\n",
            "         [ 1.5463e+00, -4.9438e-01, -1.4180e-02, -9.7428e-01,  1.3779e+00,\n",
            "           7.8648e-03, -5.3590e-01, -4.5531e-01]],\n",
            "\n",
            "        [[-3.7898e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 1.0377e-01,  1.7584e-01,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.6373e+00, -6.5557e-01, -8.5031e-01,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-2.7155e+00,  1.9022e+00, -8.4620e-01,  5.9058e-01,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 2.5044e+00, -4.9691e-01, -2.6300e-01, -1.6288e-01, -1.7459e+00,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.8634e-02,  4.9620e-01, -2.0859e-01, -8.4632e-02,  3.6811e-01,\n",
            "           7.8713e-01,        -inf,        -inf],\n",
            "         [-1.7485e+00,  4.6233e-01,  3.8654e-03,  2.1114e+00,  1.2731e+00,\n",
            "           2.1582e+00,  1.3125e+00,        -inf],\n",
            "         [-8.5500e-02, -1.5414e-02, -1.3915e+00,  6.3086e-02, -2.4530e-01,\n",
            "          -2.0677e-01, -2.2102e+00,  4.4531e-01]],\n",
            "\n",
            "        [[ 4.5165e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.0009e-01, -9.6205e-01,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.6199e-01,  5.8600e-01, -4.6738e+00,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-7.1746e-01, -1.0279e+00, -2.0509e+00, -2.7234e+00,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.0388e-01,  5.1597e-01, -2.0697e+00, -4.0982e-01, -8.0534e-01,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 8.2322e-01,  3.0237e+00, -3.0655e+00,  7.0404e-01,  6.7207e-01,\n",
            "          -4.6692e-01,        -inf,        -inf],\n",
            "         [-1.4141e+00, -1.4241e+00, -8.0387e-01, -1.7450e+00, -7.4035e-01,\n",
            "           9.8188e-01, -9.0056e-01,        -inf],\n",
            "         [-5.0277e-01,  1.6844e+00, -4.1847e-01,  1.0239e+00,  1.0275e+00,\n",
            "           1.3980e-01,  4.8822e-01,  1.5573e+00]]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "wei softmax tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
            "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
            "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
            "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
            "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
            "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
            "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
            "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
            "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "out tensor([[[-1.5713e-01,  8.8009e-01,  1.6152e-01, -7.8239e-01, -1.4289e-01,\n",
            "           7.4676e-01,  1.0068e-01, -5.2395e-01, -8.8726e-01,  1.9068e-01,\n",
            "           1.7616e-01, -5.9426e-01, -4.8124e-01, -4.8599e-01,  2.8623e-01,\n",
            "           5.7099e-01],\n",
            "         [ 6.7643e-01, -5.4770e-01, -2.4780e-01,  3.1430e-01, -1.2799e-01,\n",
            "          -2.9521e-01, -4.2962e-01, -1.0891e-01, -4.9282e-02,  7.2679e-01,\n",
            "           7.1296e-01, -1.1639e-01,  3.2665e-01,  3.4315e-01, -7.0975e-02,\n",
            "           1.2716e+00],\n",
            "         [ 4.8227e-01, -1.0688e-01, -4.0555e-01,  1.7696e-01,  1.5811e-01,\n",
            "          -1.6967e-01,  1.6217e-02,  2.1509e-02, -2.4903e-01, -3.7725e-01,\n",
            "           2.7867e-01,  1.6295e-01, -2.8951e-01, -6.7610e-02, -1.4162e-01,\n",
            "           1.2194e+00],\n",
            "         [ 1.9708e-01,  2.8561e-01, -1.3028e-01, -2.6552e-01,  6.6781e-02,\n",
            "           1.9535e-01,  2.8073e-02, -2.4511e-01, -4.6466e-01,  6.9287e-02,\n",
            "           1.5284e-01, -2.0324e-01, -2.4789e-01, -1.6213e-01,  1.9474e-01,\n",
            "           7.6778e-01],\n",
            "         [ 2.5104e-01,  7.3457e-01,  5.9385e-01,  2.5159e-01,  2.6064e-01,\n",
            "           7.5820e-01,  5.5947e-01,  3.5387e-01, -5.9338e-01, -1.0807e+00,\n",
            "          -3.1110e-01, -2.7809e-01, -9.0541e-01,  1.3181e-01, -1.3818e-01,\n",
            "           6.3715e-01],\n",
            "         [ 3.4277e-01,  4.9605e-01,  4.7248e-01,  3.0277e-01,  1.8440e-01,\n",
            "           5.8144e-01,  3.8245e-01,  2.9521e-01, -4.8969e-01, -7.7051e-01,\n",
            "          -1.1721e-01, -2.5412e-01, -6.8921e-01,  1.9795e-01, -1.5135e-01,\n",
            "           7.6659e-01],\n",
            "         [ 1.8658e-01, -9.6351e-02, -1.4300e-01,  3.0587e-01,  8.3441e-02,\n",
            "          -6.8646e-03, -2.0472e-01, -1.5350e-01, -7.6250e-02,  3.2689e-01,\n",
            "           3.0896e-01,  7.6626e-02,  9.9243e-02,  1.6560e-01,  1.9745e-01,\n",
            "           7.6248e-01],\n",
            "         [ 1.3013e-01, -3.2832e-02, -4.9645e-01,  2.8652e-01,  2.7042e-01,\n",
            "          -2.6357e-01, -7.3756e-02,  3.7857e-01,  7.4580e-02,  3.3827e-02,\n",
            "           1.4695e-02,  3.1937e-01,  2.9926e-01, -1.6530e-01, -3.8630e-02,\n",
            "           3.3748e-01]],\n",
            "\n",
            "        [[-1.3254e+00,  1.1236e+00,  2.2927e-01, -2.9970e-01, -7.6267e-03,\n",
            "           7.9364e-01,  8.9581e-01,  3.9650e-01, -6.6613e-01, -2.1844e-01,\n",
            "          -1.3539e+00,  4.1245e-01,  9.6011e-01, -1.0805e+00, -3.9751e-01,\n",
            "          -4.4439e-01],\n",
            "         [-3.8338e-01, -1.9659e-01,  8.8455e-02,  1.8560e-01, -8.7010e-02,\n",
            "           1.3239e-01,  3.0841e-01, -2.4350e-01, -1.9396e-01, -1.7634e-02,\n",
            "           4.8439e-01,  5.4210e-01, -2.0407e-02, -4.2467e-01, -2.3463e-01,\n",
            "          -4.6465e-01],\n",
            "         [-1.1100e+00,  3.2334e-01,  4.7054e-01, -6.3595e-02,  2.5443e-01,\n",
            "           1.5352e-01,  2.5186e-01,  2.6286e-01,  2.7916e-01, -3.1662e-03,\n",
            "          -3.2880e-02,  4.8191e-01,  7.4431e-01, -1.9921e-01,  2.7134e-01,\n",
            "          -8.5871e-02],\n",
            "         [-9.7190e-01,  4.6124e-01,  4.2349e-01, -1.7230e-02,  1.5847e-01,\n",
            "           4.1175e-01,  4.0764e-01,  2.4982e-01, -5.0322e-02,  4.1514e-03,\n",
            "          -3.9853e-01,  4.3551e-01,  7.0285e-01, -4.3081e-01,  2.6684e-02,\n",
            "          -2.0169e-01],\n",
            "         [ 3.3586e-01, -8.5915e-02,  9.3660e-01,  7.7311e-01,  1.8037e-01,\n",
            "           8.2853e-01, -6.9183e-02,  2.8814e-01,  1.1734e-01,  6.8448e-01,\n",
            "          -5.8500e-02,  1.2726e-01,  2.9780e-01,  1.9324e-01,  1.5655e-01,\n",
            "          -9.3005e-03],\n",
            "         [ 1.6984e-01,  3.0993e-02,  8.1557e-01,  6.1679e-01,  1.0429e-01,\n",
            "           7.4573e-01,  2.3072e-02,  3.0572e-01,  5.8163e-02,  5.7122e-01,\n",
            "          -4.5275e-02,  1.5051e-01,  3.2901e-01,  5.6984e-02,  1.0311e-01,\n",
            "          -9.9174e-02],\n",
            "         [ 4.6497e-02,  1.5765e-01,  3.9760e-01,  1.7619e-01, -2.1168e-01,\n",
            "           2.3365e-01, -6.2083e-02,  2.1726e-01, -7.8725e-03,  4.5389e-01,\n",
            "           3.4349e-01, -5.5631e-02,  3.3726e-01, -3.7591e-01, -1.0140e-02,\n",
            "          -4.5806e-01],\n",
            "         [-5.3896e-01,  7.5555e-01,  3.3034e-01, -1.5849e-01, -2.6740e-01,\n",
            "           4.3495e-01,  3.7772e-01,  5.5794e-01, -1.8369e-01,  1.5938e-01,\n",
            "          -2.1042e-01,  5.5790e-02,  6.3184e-01, -6.4884e-01, -9.6084e-02,\n",
            "          -5.0751e-01]],\n",
            "\n",
            "        [[ 6.8925e-02,  1.2248e+00, -4.1194e-01, -1.7046e-01, -6.9224e-01,\n",
            "          -2.9201e-01,  1.2704e+00, -6.8596e-01,  4.3798e-01, -2.6366e-01,\n",
            "           1.1528e-01,  1.1676e+00, -7.2138e-01, -1.2308e+00,  8.3821e-01,\n",
            "          -5.5987e-01],\n",
            "         [-4.6375e-01,  6.3807e-01, -1.5842e-01, -1.3309e-01, -5.9402e-01,\n",
            "          -5.0374e-01,  2.3289e-01, -3.2126e-01,  4.5781e-01, -1.8590e-01,\n",
            "           1.9215e-01,  3.7566e-01, -3.5905e-01, -7.7262e-01,  3.5036e-01,\n",
            "           6.9694e-02],\n",
            "         [-6.4044e-01,  1.3831e-01, -6.1007e-02, -1.1112e-01, -4.5228e-01,\n",
            "          -6.2271e-01, -1.7030e-01, -2.4949e-01,  5.0670e-01, -9.6444e-02,\n",
            "           4.8315e-01,  9.4986e-02, -2.9810e-01, -3.6538e-01,  3.9458e-01,\n",
            "           4.1512e-01],\n",
            "         [-6.7193e-01,  1.2516e-01,  7.3386e-02, -1.3198e-01, -1.7880e-01,\n",
            "          -5.6740e-01, -6.8226e-01,  5.0844e-02,  3.3051e-01,  7.8242e-02,\n",
            "           6.8022e-02, -2.4041e-01, -6.6864e-02, -1.8411e-01, -5.3514e-02,\n",
            "           4.5113e-01],\n",
            "         [-1.4270e-02,  1.0195e+00, -3.4792e-01, -1.6421e-01, -5.5846e-01,\n",
            "          -3.2457e-01,  9.9404e-01, -5.6891e-01,  4.0097e-01, -1.8123e-01,\n",
            "           1.1856e-01,  9.8704e-01, -6.4057e-01, -1.0320e+00,  7.3320e-01,\n",
            "          -4.3167e-01],\n",
            "         [-6.3858e-01, -7.6533e-02, -3.6510e-01,  1.7782e-01, -6.5426e-02,\n",
            "          -3.5158e-01,  7.9591e-02,  1.7384e-01,  3.6676e-01, -4.2302e-02,\n",
            "           2.4923e-01,  4.8239e-01, -2.1295e-01, -2.9492e-01,  3.4749e-01,\n",
            "          -1.7111e-01],\n",
            "         [-2.2366e-01, -5.5317e-02, -1.8296e-01,  2.4258e-01,  2.5357e-01,\n",
            "          -1.6154e-01, -2.3908e-01,  3.3243e-01,  1.0304e-01,  2.6067e-01,\n",
            "          -5.0670e-02,  3.6947e-01, -4.9856e-02,  1.1197e-01,  1.1752e-01,\n",
            "          -2.5078e-01],\n",
            "         [-2.4821e-01,  1.4845e-01, -3.5033e-01,  1.7102e-01,  1.6613e-01,\n",
            "          -2.0643e-01,  8.6633e-02,  8.8414e-02,  2.1188e-01,  2.5805e-01,\n",
            "           5.5145e-02,  4.2668e-01, -2.0443e-01, -1.7372e-01,  3.8899e-01,\n",
            "           5.1725e-02]],\n",
            "\n",
            "        [[ 9.7183e-02,  5.7301e-02, -1.0468e-01, -4.6654e-02, -1.4006e-01,\n",
            "          -8.4126e-01, -1.3625e-01, -6.7465e-01, -2.1541e-01,  1.0993e+00,\n",
            "           2.3427e-01,  3.2605e-02, -1.8521e-01,  1.4780e-01, -6.1045e-01,\n",
            "           1.5391e+00],\n",
            "         [ 1.9305e-01, -2.1031e-01, -3.4658e-01,  2.0567e-01, -1.7799e-01,\n",
            "          -7.4604e-01, -6.4427e-01, -6.9183e-01, -2.0558e-01,  7.0413e-01,\n",
            "           2.3632e-01,  9.8800e-04, -1.7015e-01,  1.1203e-01, -7.1064e-01,\n",
            "           1.2431e+00],\n",
            "         [ 2.9114e-01, -4.8343e-01, -5.9254e-01,  4.6477e-01, -2.1832e-01,\n",
            "          -6.4460e-01, -1.1627e+00, -7.0993e-01, -1.9703e-01,  2.9262e-01,\n",
            "           2.3669e-01, -3.1050e-02, -1.5471e-01,  7.7153e-02, -8.1137e-01,\n",
            "           9.3578e-01],\n",
            "         [ 1.7549e-01, -3.4260e-02, -2.0523e-01,  2.7644e-02, -2.1312e-01,\n",
            "          -5.6022e-01, -3.5273e-01, -6.2722e-01, -3.0037e-01,  4.6061e-01,\n",
            "           1.5004e-01,  1.9040e-02, -1.4646e-01,  1.7220e-01, -6.2559e-01,\n",
            "           1.0722e+00],\n",
            "         [ 1.7354e-01, -1.7962e-01, -2.7874e-01, -1.0590e-01, -1.2952e-01,\n",
            "          -3.5086e-01, -5.5830e-01, -3.8638e-01, -2.9719e-01,  3.3368e-02,\n",
            "           1.7392e-01,  5.5898e-02, -7.2007e-02,  1.3182e-02, -6.6710e-01,\n",
            "           5.4229e-01],\n",
            "         [ 2.4678e-01, -4.7274e-01, -5.2827e-01,  3.1212e-01, -1.7528e-01,\n",
            "          -4.8636e-01, -1.1223e+00, -5.4196e-01, -2.0142e-01,  4.0103e-02,\n",
            "           2.2231e-01, -2.9380e-02, -9.4354e-02,  2.6374e-02, -7.8726e-01,\n",
            "           6.2836e-01],\n",
            "         [-3.9784e-01,  2.5915e-01,  5.0358e-01, -4.6864e-01, -2.2024e-02,\n",
            "          -3.2242e-01, -1.2578e-01,  1.0634e-01,  1.3618e-01,  1.7780e-01,\n",
            "           1.0391e-01, -6.2540e-01,  3.8904e-01,  3.3690e-01, -5.5140e-01,\n",
            "           5.2246e-01],\n",
            "         [-3.5927e-01,  3.3935e-02, -2.9863e-02, -1.5019e-01, -6.0354e-03,\n",
            "          -6.5733e-02, -3.9659e-01, -6.0435e-02, -5.7551e-01, -2.9157e-01,\n",
            "           1.4899e-01, -7.5002e-02,  7.3228e-02, -4.7413e-02, -6.4394e-01,\n",
            "           2.8560e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. attention is communication mechanism.\n",
        "2. we have 8 nodes , block size is 8,\n",
        "3. no notion of space, attention simply acts over a set of vectors, that's why we use positional encoding\n",
        "4. elements across the batch dimension never talk to each other\n",
        "5. in encoder attention block just delete the single line that does tril, allowing tokens to communicate . above traingular block is used in autoregressive settings, like language modelling.\n",
        "6. self attention because keys queries and values all come from x, in cross attention, queries come from x but keys and values come from different sources"
      ],
      "metadata": {
        "id": "8Kar1AsUKBqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled attention , to normalize the keys , queries and values\n",
        "\n",
        "k=torch.rand(B,T,head_size)\n",
        "q=torch.rand(B,T,head_size)\n",
        "wei=q @ k.transpose(-2,-1) *head_size**-0.5"
      ],
      "metadata": {
        "id": "ADKHAZeBFdrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sonL4f-LrYW",
        "outputId": "32262d46-163f-45d3-a206-ba353c1f487e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0763)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0rgrY_YLyn9",
        "outputId": "b5d1d67c-cd70-489d-a46d-f271f7d08307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0808)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw9JLtUjLz_I",
        "outputId": "58dcfa86-8fc8-4882-f94d-32ec94428d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0443)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEcg1etFL1rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 2\n"
      ],
      "metadata": {
        "id": "1zJbal3DPcPs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8C11-MpPdfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open(\"input.txt\", \"r\", encoding= \"utf-8\") as f:\n",
        "  text=f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KydEz2fMPeFk",
        "outputId": "88008d09-e4e8-4408-a6cf-03080417399e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 14:56:53--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-03-24 14:56:53 (27.2 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "# hyperparameters\n",
        "batch_size=64\n",
        "block_size=256\n",
        "max_iters=5000\n",
        "eval_interval=500\n",
        "learning_rate=3e-4\n",
        "device='cuda' if torch.cuda.is_available else 'cpu'\n",
        "# device='cpu'\n",
        "eval_iters=200\n",
        "n_embed=384\n",
        "n_head=6\n",
        "n_layer=6\n",
        "dropout=0.2\n",
        "# =====================\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "\n",
        "with open(\"input.txt\", \"r\", encoding= \"utf-8\") as f:\n",
        "  text=f.read()\n",
        "\n",
        "# here are all the inique characters that occur inthe text\n",
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)\n",
        "\n",
        "# Create a mappping from characters to integers\n",
        "stoi={ ch:i for i, ch in enumerate(chars) }\n",
        "itos={ i:ch for i, ch in enumerate(chars) }\n",
        "encode=lambda s: [stoi[c] for c in s] #encoder takes a string, outputs a list of integers\n",
        "decode=lambda l: ''.join([itos[i] for i in l]) # decoder: takes a list of integers, outputs a string\n",
        "\n",
        "# Train and test set splits\n",
        "data=torch.tensor(encode(text), dtype=torch.long)\n",
        "n=int(0.9*len(data)) # first 90% will be train, rest will be val\n",
        "train_data=data[:n]\n",
        "val_data=data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "  # generate a small batch of ata of inputs x and targets y\n",
        "  data=train_data if split==\"train\" else val_data\n",
        "  ix=torch.randint(len(data)-block_size, (batch_size,))\n",
        "  x=torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  x,y=x.to(device), y.to(device)\n",
        "  return x,y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out={}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses=torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      # sample a batch of data\n",
        "      X,Y=get_batch(split)\n",
        "      logits, loss=model(X,Y)\n",
        "      losses[k]=loss.item()\n",
        "    out[split]=losses.mean()\n",
        "  model.train()\n",
        "  return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self,head_size):\n",
        "      super().__init__()\n",
        "      self.key=nn.Linear(n_embed, head_size, bias=False)\n",
        "      self.query=nn.Linear(n_embed, head_size, bias=False)\n",
        "      self.value=nn.Linear(n_embed, head_size, bias=False)\n",
        "      self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "      self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "      B,T,C=x.shape\n",
        "      k=self.key(x)\n",
        "      q=self.query(x)\n",
        "\n",
        "      # compute attention scores (\"affinities\")\n",
        "      wei=q @ k.transpose(-2,-1) * C**-0.5  # (B,T,C) @ (B,C,T) ----> (B,T,T)\n",
        "      wei=wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B,T,T)\n",
        "      wei=F.softmax(wei, dim=-1) #(B,T,T)\n",
        "      wei=self.dropout(wei)\n",
        "      # perform the weighted aggregation of the values\n",
        "      v=self.value(x) #(B,T,C)\n",
        "      out=wei@v #(B,T,T) @ (B,C,T) ---> (B,T,C)\n",
        "      return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\" multiple heads of self attention in parallel \"\"\"\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super().__init__()\n",
        "    self.heads=nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "    self.proj=nn.Linear(head_size*num_heads, n_embed)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out=torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    out=self.dropout(self.proj(out))\n",
        "    return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  \"\"\" a simple linear layer followed by a non linearity \"\"\"\n",
        "\n",
        "  def __init__(self, n_embed):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(\n",
        "      nn.Linear(n_embed, 4*n_embed),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(4*n_embed, n_embed),\n",
        "      nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "  \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "  def __init__(self, n_embed, n_head):\n",
        "    super().__init__()\n",
        "    head_size=n_embed//n_head\n",
        "    self.sa=MultiHeadAttention(n_head, n_head)\n",
        "    self.ffwd=FeedForward(n_embed)\n",
        "    self.ln1=nn.LayerNorm(n_embed)\n",
        "    self.ln2=nn.LayerNorm(n_embed)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=x+self.sa(self.ln1(x))\n",
        "    x=x+self.ffwd(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size, n_embed)\n",
        "    self.position_embedding_table=nn.Embedding(block_size, n_embed)\n",
        "\n",
        "    # self.sa_head=MultiHeadAttention(4,n_embed//4)# i.e. 4 heads of 8 dimensional self-attention\n",
        "    # self.ffwd=FeedForward(n_embed)\n",
        "\n",
        "    # replace with blocks\n",
        "    # self.blocks=nn.Sequential(\n",
        "    #   Block(n_embed, n_head=4),\n",
        "    #   Block(n_embed, n_head=4),\n",
        "    #   Block(n_embed, n_head=4),\n",
        "    #   nn.LayerNorm(n_embed)\n",
        "    # )\n",
        "    self.blocks=nn.Sequential(*[Block(n_embed, n_head=n_head) for _ in range(n_layer)])\n",
        "    self.lm_head=nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    B,T=idx.shape\n",
        "    token_emb=self.token_embedding_table(idx) # (B,T,C)\n",
        "    pos_emb=self.position_embedding_table(torch.arange(T ,device=device)) #(T,C)\n",
        "    x=token_emb+pos_emb # (B,T,C)\n",
        "\n",
        "    # x=self.sa_head(x) # apply one head of self attention (B,T,C)\n",
        "    # x=self.ffwd(x)\n",
        "\n",
        "    # replace with blocks\n",
        "    x=self.blocks(x) # (B,T,C)\n",
        "    logits=self.lm_head(x)# (B,T, vocab_size)\n",
        "    if targets is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      # pytorch expects()\n",
        "      B,T,C=logits.shape\n",
        "      logits=logits.view(B*T, C)\n",
        "      targets=targets.view(B*T)\n",
        "      loss=F.cross_entropy(logits, targets)\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      # crop idz to the last block size tokens\n",
        "      idx_cond=idx[:, -block_size:]\n",
        "      # get the predictions\n",
        "      logits,loss=self(idx_cond)\n",
        "      # focus only on last time step\n",
        "      logits=logits[:,-1,:] #becomes (B,C)\n",
        "      # apply softmax to get probabilities\n",
        "      probs=F.softmax(logits, dim=-1) #(B,C)\n",
        "      # sample the distribution\n",
        "      idx_next=torch.multinomial(probs, num_samples=1) #(B,1)\n",
        "      # append sampled index to the running sequence\n",
        "      idx=torch.cat((idx, idx_next), dim=1) # (B,T+1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "model=BigramLanguageModel()\n",
        "m=model.to(device)\n",
        "\n",
        "optimizer=torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "  if iter%eval_interval ==0:\n",
        "    losses=estimate_loss()\n",
        "    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "  xb,yb=get_batch('train')\n",
        "  logits,loss=model(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "context=torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(context.to(device), max_new_tokens=300)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AqlpYSgPeIv",
        "outputId": "c36a557b-6977-45fb-bde9-20b8c727e1f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.6302, val loss 4.6157\n",
            "step 500: train loss 2.3686, val loss 2.3941\n",
            "step 1000: train loss 1.9829, val loss 2.0691\n",
            "step 1500: train loss 1.7553, val loss 1.9047\n",
            "step 2000: train loss 1.6178, val loss 1.7911\n",
            "step 2500: train loss 1.5298, val loss 1.7190\n",
            "step 3000: train loss 1.4702, val loss 1.6691\n",
            "step 3500: train loss 1.4226, val loss 1.6277\n",
            "step 4000: train loss 1.3871, val loss 1.6066\n",
            "step 4500: train loss 1.3558, val loss 1.5821\n",
            "\n",
            "But with the opperon to steeast-night fomerful.\n",
            "\n",
            "AEdils:\n",
            "Away:\n",
            "Thu'll k not your hellord's wiself goood in\n",
            "to Have want my inheard than abroad fecure\n",
            "To you beg the usitomer eremas and you\n",
            "slewst my recomplexion men in right;\n",
            "My missed 'I bured your own then hence of it\n",
            "soverd the telw, I do subto f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kfnVniR6PtRF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}