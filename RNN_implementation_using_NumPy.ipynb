{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmhN7Juv3HEgxnTFr77jzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/developerabhi14/ML-Notebooks/blob/main/RNN_implementation_using_NumPy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Implementation using Numpy\n"
      ],
      "metadata": {
        "id": "8jmzALVL_V5w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-d88zd55-g7s"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: \"hello\"\n",
        "char_to_index = {'h': 0, 'e': 1, 'l': 2, 'o': 3}\n",
        "index_to_char = {0: 'h', 1: 'e', 2: 'l', 3: 'o'}\n",
        "text = \"hello\""
      ],
      "metadata": {
        "id": "GnE76RUa-ll2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(char_to_index)  # 4 (one-hot encoded)\n",
        "hidden_size = 8 # You can change it!\n",
        "output_size = len(char_to_index) # 4"
      ],
      "metadata": {
        "id": "6Hjav1NS-rG_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U = np.random.randn(hidden_size, input_size) * 0.01  # Input to hidden\n",
        "W = np.random.randn(hidden_size, hidden_size) * 0.01 # Hidden to hidden\n",
        "V = np.random.randn(output_size, hidden_size) * 0.01 # Hidden to output\n",
        "\n",
        "# Bias vectors\n",
        "b = np.zeros((hidden_size, 1)) # Hidden bias\n",
        "c = np.zeros((output_size, 1)) # Output bias"
      ],
      "metadata": {
        "id": "ajy0gyPP-vBN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(inputs, h_prev):\n",
        "    x = np.zeros((input_size, 1)) # Create vector for input\n",
        "    x[inputs] = 1 # One hot encode current input\n",
        "    h = np.tanh(np.dot(U, x) + np.dot(W, h_prev) + b) # Get the current hidden state\n",
        "    o = np.dot(V, h) + c # Predict the output\n",
        "    y_hat = np.exp(o) / np.sum(np.exp(o)) # Use softmax function to get probabilities for all output classes\n",
        "\n",
        "    return y_hat, h\n"
      ],
      "metadata": {
        "id": "23Kg4TT6-xcU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_hat, target_index):\n",
        "    return -np.log(y_hat[target_index, 0])"
      ],
      "metadata": {
        "id": "jZzJuSog-3AM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_pass(y_hat, target_index, h, h_prev, x):\n",
        "    # Gradients of output layer\n",
        "    do = np.copy(y_hat) # copy y_hat to do\n",
        "    do[target_index] -= 1 # Subtract 1 on the output vector\n",
        "    dV = np.dot(do, h.T) # Gradient of V\n",
        "    dc = do # Gradient of c\n",
        "\n",
        "    dh = np.dot(V.T, do) # Gradient of hidden layer\n",
        "    dhraw = (1 - h * h) * dh # Gradient of raw hidden layer\n",
        "\n",
        "    db = dhraw # Gradient of b\n",
        "    dU = np.dot(dhraw, x.T) # Gradient of U\n",
        "    dW = np.dot(dhraw, h_prev.T) # Gradient of W\n",
        "\n",
        "    return dU, dW, dV, db, dc"
      ],
      "metadata": {
        "id": "evPDXIZg-7Nz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "learning_rate = 0.1\n",
        "n_epochs = 100\n",
        "\n",
        "h_prev = np.zeros((hidden_size, 1)) # Initiate the hidden layer\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss = 0\n",
        "    dU, dW, dV, db, dc = np.zeros_like(U), np.zeros_like(W), np.zeros_like(V), np.zeros_like(b), np.zeros_like(c) # Initialize the derivatives\n",
        "\n",
        "    for t in range(len(text) - 1):\n",
        "        inputs = char_to_index[text[t]] # Get the input from text data\n",
        "        target_index = char_to_index[text[t+1]] # Get the target\n",
        "        x = np.zeros((input_size, 1)) # Create vector for input\n",
        "        x[inputs] = 1 # One hot encode current input\n",
        "\n",
        "        # Forward pass\n",
        "        y_hat, h_prev = forward_pass(inputs, h_prev) # One forward pass\n",
        "\n",
        "        # Calculate loss\n",
        "        loss += cross_entropy_loss(y_hat, target_index) # Calculate cross entropy loss\n",
        "\n",
        "        # Backpropagation\n",
        "        current_dU, current_dW, current_dV, current_db, current_dc = backward_pass(y_hat, target_index, h_prev, h_prev, x)\n",
        "\n",
        "        # Sum the gradients\n",
        "        dU += current_dU\n",
        "        dW += current_dW\n",
        "        dV += current_dV\n",
        "        db += current_db\n",
        "        dc += current_dc\n",
        "\n",
        "    # Update parameters\n",
        "    U -= learning_rate * dU\n",
        "    W -= learning_rate * dW\n",
        "    V -= learning_rate * dV\n",
        "    b -= learning_rate * db\n",
        "    c -= learning_rate * dc\n",
        "\n",
        "    # Print loss every epoch\n",
        "    print('Epoch:', epoch+1, 'Loss =', loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEdxkAxd--17",
        "outputId": "f5ca7f37-4864-42c4-9639-517ca88cf126"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss = 5.545382814249162\n",
            "Epoch: 2 Loss = 5.354954398014552\n",
            "Epoch: 3 Loss = 5.2005847192089645\n",
            "Epoch: 4 Loss = 5.075195278970911\n",
            "Epoch: 5 Loss = 4.972962568681064\n",
            "Epoch: 6 Loss = 4.889139287775643\n",
            "Epoch: 7 Loss = 4.819895676638067\n",
            "Epoch: 8 Loss = 4.762171158293414\n",
            "Epoch: 9 Loss = 4.7135372886093485\n",
            "Epoch: 10 Loss = 4.67207520644026\n",
            "Epoch: 11 Loss = 4.636269706707246\n",
            "Epoch: 12 Loss = 4.604920264816385\n",
            "Epoch: 13 Loss = 4.57706789246887\n",
            "Epoch: 14 Loss = 4.551935862777016\n",
            "Epoch: 15 Loss = 4.528882023779998\n",
            "Epoch: 16 Loss = 4.50736045275451\n",
            "Epoch: 17 Loss = 4.486890436967573\n",
            "Epoch: 18 Loss = 4.467031096704478\n",
            "Epoch: 19 Loss = 4.447360337722577\n",
            "Epoch: 20 Loss = 4.427457212910774\n",
            "Epoch: 21 Loss = 4.406887191488078\n",
            "Epoch: 22 Loss = 4.385190297627041\n",
            "Epoch: 23 Loss = 4.361872612571785\n",
            "Epoch: 24 Loss = 4.336402250198583\n",
            "Epoch: 25 Loss = 4.308211601321883\n",
            "Epoch: 26 Loss = 4.276708320640965\n",
            "Epoch: 27 Loss = 4.241298017269559\n",
            "Epoch: 28 Loss = 4.201421559133063\n",
            "Epoch: 29 Loss = 4.156608775422184\n",
            "Epoch: 30 Loss = 4.106547470136935\n",
            "Epoch: 31 Loss = 4.051161505855019\n",
            "Epoch: 32 Loss = 3.9906844648109674\n",
            "Epoch: 33 Loss = 3.9257078389065727\n",
            "Epoch: 34 Loss = 3.857178929320903\n",
            "Epoch: 35 Loss = 3.786329279709948\n",
            "Epoch: 36 Loss = 3.714533156667184\n",
            "Epoch: 37 Loss = 3.6431234045275143\n",
            "Epoch: 38 Loss = 3.5732150431423273\n",
            "Epoch: 39 Loss = 3.505588563219261\n",
            "Epoch: 40 Loss = 3.440660112341396\n",
            "Epoch: 41 Loss = 3.378528902988014\n",
            "Epoch: 42 Loss = 3.319065773169715\n",
            "Epoch: 43 Loss = 3.2620031285556115\n",
            "Epoch: 44 Loss = 3.20700080137768\n",
            "Epoch: 45 Loss = 3.153681799650111\n",
            "Epoch: 46 Loss = 3.1016462262491133\n",
            "Epoch: 47 Loss = 3.050476627331019\n",
            "Epoch: 48 Loss = 2.99974399145784\n",
            "Epoch: 49 Loss = 2.9490141387735016\n",
            "Epoch: 50 Loss = 2.897846256064093\n",
            "Epoch: 51 Loss = 2.8457782561500196\n",
            "Epoch: 52 Loss = 2.792315832217933\n",
            "Epoch: 53 Loss = 2.736983515420189\n",
            "Epoch: 54 Loss = 2.6795306586654033\n",
            "Epoch: 55 Loss = 2.6203326719931668\n",
            "Epoch: 56 Loss = 2.5608099001924063\n",
            "Epoch: 57 Loss = 2.5037297404294763\n",
            "Epoch: 58 Loss = 2.4557869484427535\n",
            "Epoch: 59 Loss = 2.44662885567998\n",
            "Epoch: 60 Loss = 2.643986250919886\n",
            "Epoch: 61 Loss = 3.729927045019659\n",
            "Epoch: 62 Loss = 2.282757864731163\n",
            "Epoch: 63 Loss = 3.2981046276211954\n",
            "Epoch: 64 Loss = 3.974095348405389\n",
            "Epoch: 65 Loss = 2.4022729948661063\n",
            "Epoch: 66 Loss = 2.127159888496444\n",
            "Epoch: 67 Loss = 1.9652651707111342\n",
            "Epoch: 68 Loss = 1.9159185169901973\n",
            "Epoch: 69 Loss = 1.9109810295220746\n",
            "Epoch: 70 Loss = 1.7588508842336212\n",
            "Epoch: 71 Loss = 1.418711640754771\n",
            "Epoch: 72 Loss = 1.3495102246206472\n",
            "Epoch: 73 Loss = 1.3302256030581439\n",
            "Epoch: 74 Loss = 1.1900652588946967\n",
            "Epoch: 75 Loss = 1.2338173331466553\n",
            "Epoch: 76 Loss = 1.0796173675714777\n",
            "Epoch: 77 Loss = 1.5464332716095457\n",
            "Epoch: 78 Loss = 1.5095277288345825\n",
            "Epoch: 79 Loss = 6.072403191259393\n",
            "Epoch: 80 Loss = 1.9718469812282737\n",
            "Epoch: 81 Loss = 2.766650874390992\n",
            "Epoch: 82 Loss = 5.309218939806157\n",
            "Epoch: 83 Loss = 3.1616169896650828\n",
            "Epoch: 84 Loss = 3.7377077321258225\n",
            "Epoch: 85 Loss = 2.6441339733199185\n",
            "Epoch: 86 Loss = 2.4023464025161254\n",
            "Epoch: 87 Loss = 2.3776410796839715\n",
            "Epoch: 88 Loss = 2.097917553256938\n",
            "Epoch: 89 Loss = 2.212965973047813\n",
            "Epoch: 90 Loss = 2.0643487702922867\n",
            "Epoch: 91 Loss = 2.1337578813206206\n",
            "Epoch: 92 Loss = 2.125948635126142\n",
            "Epoch: 93 Loss = 2.120914028228801\n",
            "Epoch: 94 Loss = 2.1929068822569318\n",
            "Epoch: 95 Loss = 2.154075311185935\n",
            "Epoch: 96 Loss = 2.239040411732689\n",
            "Epoch: 97 Loss = 2.2084809593238206\n",
            "Epoch: 98 Loss = 2.2843324392583884\n",
            "Epoch: 99 Loss = 2.2370775614696963\n",
            "Epoch: 100 Loss = 2.3566823986582417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "h_prev = np.zeros((hidden_size, 1))\n",
        "predicted_text = 'e'\n",
        "for t in range(len(text) - 1):\n",
        "    inputs = char_to_index[text[t]]\n",
        "    y_hat, h_prev = forward_pass(inputs, h_prev)\n",
        "    predicted_index = np.argmax(y_hat)\n",
        "    predicted_text += index_to_char[predicted_index]\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXC6OmAW_B9g",
        "outputId": "881beec5-78da-40c6-c2dc-6e35635271fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDGNSWx3_Fnc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}